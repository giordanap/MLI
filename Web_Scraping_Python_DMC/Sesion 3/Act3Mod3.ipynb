{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Act3Mod3.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PMYjyI0ODYhk","colab_type":"text"},"source":["## Actividad 3: Scrapear Frases v2.0\n","\n","En esta actividad 3 del módulo 3 scrapearemos un ecommerce extranjero.\n","\n","Es importante que nos guiemos de la documentación: https://docs.scrapy.org/en/latest/ para saber qué está ocurriendo en el código y aprender nuevas formas de ejecutar el scraping"]},{"cell_type":"markdown","metadata":{"id":"CHAapvpBDccg","colab_type":"text"},"source":["Con el código que vemos debajo podemos asegurarnos de instalar scrapy si es que no lo tenemos. Luego procedemos a importar el crawler que utilizaremos."]},{"cell_type":"code","metadata":{"id":"tEKnFMmeDDl0","colab_type":"code","colab":{}},"source":["try:\n","    import scrapy\n","except:\n","    !pip install scrapy\n","    import scrapy\n","from scrapy.crawler import CrawlerProcess\n","import re\n","import logging"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VJLRT3dQDh0Y","colab_type":"text"},"source":["Diseñamos la estructura de nuestro Item."]},{"cell_type":"code","metadata":{"id":"ROZ1fI_xDj43","colab_type":"code","colab":{}},"source":["class EcommerceItem(scrapy.Item):\n","  title = scrapy.Field()\n","  cat = scrapy.Field()\n","  price = scrapy.Field()\n","  descr = scrapy.Field()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iXLXcAGkDerv","colab_type":"text"},"source":["Diseñamos las funciones de nuestro Pipeline.\n","* ```process_item``` es la función que se llama para procesar el objeto.\n","* ```remove_tags``` es una función personalizada"]},{"cell_type":"code","metadata":{"id":"wnV9gDzeEgeO","colab_type":"code","colab":{}},"source":["class EcommercePipeline(object):\n","    def process_item(self, item, spider):\n","        return item\n","    \n","    def remove_tags(self, text):\n","        html_tags = re.compile('<.*?>')\n","        return re.sub(html_tags, '', text)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rE5Kuf5vI5Qh","colab_type":"text"},"source":["Una vez tenemos definida nuestra Pipeline, procedemos a definir nuestro propio Spider. Atención a las ```custom_settings```."]},{"cell_type":"code","metadata":{"id":"vPFJd2RcF3jW","colab_type":"code","colab":{}},"source":["class EcommerceSpider(scrapy.Spider):\n","    name = 'EcommerceSpider'\n","    allowed_domains = ['HarveyNorman.com.au']\n","    start_urls = ['https://www.HarveyNorman.com.au/']\n","\n","    custom_settings = {\n","        'LOG_LEVEL': logging.WARNING, # Con esto reducimos el número de mensajes que recibimos\n","        'ITEM_PIPELINES': {'__main__.EcommercePipeline': 1}, # Ejecuta nuestra Pipeline\n","        'FEED_FORMAT':'csv',                                 # Almacenamos la información de nuestra Pipeline\n","        'FEED_URI': 'ecommerce.csv'\n","    }\n","\n","    def __init__(self):\n","        self.getAllCategoriesXpath = \"//div[@id='wrapper']/div[1]/div[1]/div[1]/div[1]/div[contains(@class, 'col-md-3')]/ul/li/a/@href\"\n","        self.getAllSubCategoriesXpath = \"//*[@id='content']/div[2]/div[1]/div/div[2]/div/div/div/div[2]/div/a/@href\"\n","        self.getAllItemsXpath = \"//*[@id='category-grid']/div/div/div[3]/a/@href\"\n","        self.titleXpath  = \"//*[@id='overview']/div[1]/h1/span[1]/text()\"\n","        self.categoryXpath = \"//*[@id='breadcrumbs']/li/a/text()\"\n","        self.priceXpath = \"//div[contains(@class, 'product-view-sales')]//span[@class='price']/text()\"\n","        self.descriptionXpath = \"//*[@id='tab-content-product-description']/div/div[contains(@class,'description')][1]/p//text()\"\n","    \n","    def parse(self, response):\n","        for href in response.xpath(self.getAllItemsXpath):\n","            url = response.urljoin(href.extract())\n","            yield scrapy.Request(url,callback=self.parse_main_item, dont_filter=True)\n","\n","    def parse_main_item(self,response):\n","        item = EcommerceItem()\n","\n","        title = response.xpath(self.titleXpath).extract()\n","        category = response.xpath(self.categoryXpath).extract()\n","        price = response.xpath(self.priceXpath).extract()\n","        description = response.xpath(self.descriptionXpath).extract()\n","\n","        item['title'] = title\n","        item['cat'] = category\n","        item['price'] = price\n","        item['descr'] = description\n","        return item"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8q2cBBtHHRyM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"0b0d1db9-c522-4e96-a2f3-60846abcade3","executionInfo":{"status":"ok","timestamp":1574109123048,"user_tz":300,"elapsed":5529,"user":{"displayName":"Paulo César Tuya Rodríguez","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD4rzD3o9u8d1YZ_z6CREQ-gTZHiqDpoTBn0Q2i=s64","userId":"04235752306420880561"}}},"source":["process = CrawlerProcess()\n","\n","process.crawl(EcommerceSpider)\n","process.start()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["2019-11-18 20:31:57 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: scrapybot)\n","2019-11-18 20:31:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.6.8 (default, Oct  7 2019, 12:59:55) - [GCC 8.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\n","2019-11-18 20:31:57 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'csv', 'FEED_URI': 'ecommerce.csv', 'LOG_LEVEL': 30}\n"],"name":"stderr"}]}]}